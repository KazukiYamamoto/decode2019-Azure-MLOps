{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat_minor": 2,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# クラウドへ（そしてその先へ）\n数値の問題を解決する方法については十分に検討しました。トレーニング部分をクラウドに移行します。この場合も同様です。（数値の問題にはこれ以上は不要ですが、他の問題については、ローカルでサブセットの問題をテストしてからクラウドに移動して全体を処理します）\n\nいくつか設定しましょう。\n\n最初にしなければならないことは、azureml.core パッケージがノートブック環境にインストールされているのを確認することです。Azure Notebooksを使用している場合は、簡単な2ステップのプロセスで確認できます。",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Azure Notebooks に依存関係を追加する\n\"Project Settings\" をクリックします。\n\n![Project Setings](https://raw.githubusercontent.com/sethjuarez/pytorchintro/master/images/project_settings.png)\n\n次に、\"Environments\" タブを選択し、\"Python 3.6\" を選択します。最後に、`requirements.txt` を選択します。\n\n![Settings](https://raw.githubusercontent.com/sethjuarez/pytorchintro/master/images/settings.png)\n\nこれらのステップで、実行できるようになるはずです。\n\n注: もし上記の設定をしても問題が発生する場合は、Notebook でカーネルが Python 3.6 に設定されていることを確認してください。次の操作で設定できます:\nSelect Kernel - Change Kernel - Python 3.6",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import json\nimport time\nimport azureml\nfrom azureml.core.model import Model\nfrom azureml.core import Workspace, Run, Experiment\nfrom azureml.core.runconfig import RunConfiguration\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.compute_target import ComputeTargetException\nfrom azureml.train.dnn import PyTorch\nfrom azureml.widgets import RunDetails\nfrom torchvision import datasets, transforms\n\nprint(\"Azure ML SDK Version: \", azureml.core.VERSION)",
      "metadata": {},
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Azure ML SDK Version:  1.0.2\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "# Azure Machine Learning サービスを設定する\n最初に必要な作業は、Azure Machine Learning ワークスペースを作成することです。その方法についての [ドキュメント](https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-get-started#create-a-workspace) があります。コマンドラインタイプに慣れている場合は、Azure CLI を使用してセットアップする方法の [例](https://github.com/sethjuarez/workspacestarter) があります。プロジェクトを設定したら、以下のコードのコメントを外して設定ファイルを書き出し、ワークスペースに適した設定を入力します。設定ファイルが書き出されたら、下記のようにプログラムでワークスペースをロードすることができます。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "##use this code to set up config file\n#subscription_id ='<SUB_ID>'\n#resource_group ='<RESOURCE_GROUP>'\n#workspace_name = '<WORKSPACE>'\n\n#try:\n#    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n#    ws.write_config()\n#    print('Workspace configuration succeeded. You are all set!')\n#except:\n#    print('Workspace not found. TOO MANY ISSUES!!!')\n\n##once you run the above code once, you can use the written config\nws = Workspace.from_config()",
      "metadata": {},
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Found the config file in: C:\\projects\\pytorchintro\\aml_config\\config.json\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "# クラウドコンピュート\n次に、実験用のコンピュートターゲットを定義する必要があります。これはまったく新しいワークスペースなので、クラスタの名前を変更してください（私は 'racer' と呼んでいます）。以下のコードは自分のクラスタへの参照を取得しようとしますが、存在しない場合は作成します。クラスタを作成する場合、少し時間がかかります。また、予想外の課金をされないように、実験が完了したらクラスターをオフにしてください（実際には、min_node を 0 に設定して、長時間アイドル状態になるとクラスタが自動的にオフになることを検討してください）。 ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "cluster = 'racer'\ntry:\n    compute = ComputeTarget(workspace=ws, name=cluster)\n    print('Found existing compute target \"{}\"'.format(cluster))\nexcept ComputeTargetException:\n    print('Creating new compute target \"{}\"...'.format(cluster))\n    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', min_nodes=1, max_nodes=6)\n    compute = ComputeTarget.create(ws, cluster, compute_config)\n    compute.wait_for_completion(show_output=True)",
      "metadata": {},
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Found existing compute target \"racer\"\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "# 実験の時間\nコンピューティングターゲットが設定されたら、前回の小さなノートブックをリモートコンピューティング環境で実行できる単一のスクリプトにパッケージ化します。[あなたのために](train.py) 作っておきました。実際、ファイルを見ると、前のノートブックから学んだものとまったく同じ概念がすべて表示されます（これはほとんどまったく同じですが、スクリプトへの受け渡しを容易にするために追加の事項を入れています）。\n\nAzure ML サービスには実験という概念があります。実験ごとに複数回実行することができます。ここでは、実験の実行方法を定義する Estimator オブジェクトを使用しています。\n\n### バックグラウンドで何をしてるか気にしないのであれば、ここを読んではいけません\nバックグラウンドでは、Estimator は基本的に実験を格納する docker イメージの定義です。このすべてについての最もよい部分は、あなたがあなたの実験に使うもの（TensorFlowの狂ったカスタムバージョンであっても他の何かであっても）に関係なく、それが必ず実行可能であるということです - 結局それはコンテナです。とても使いやすいです。\n\n### 通常の手順に戻る\nEstimator を Azure ML サービスで実行することを送信すると、現在のディレクトリの内容がコピーされ、新しいコンテナにまとめられます（それらは [.amlignore] ファイルに記述されたもの以外、全部アップロードされます）\n\nまた、'argparse' を使用しているので、推論器定義の一部としてトレーニングスクリプトに外部パラメータを指定できます。\n\n次の3行を実行して、何が起こるのか見てみましょう。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Create and run experiment\nmnist = Experiment(ws, 'pytorchmnist')\n\n# script parameters\nscript_params={\n    '--epochs': 5,\n    '--batch': 100,\n    '--lr': .001,\n    '--model': 'cnn'\n}\n\n# Create Estimator\nestimator = PyTorch(source_directory='.',\n                       compute_target=compute, \n                       entry_script='train.py',\n                       script_params=script_params,\n                       use_gpu=True)\n\nrun = mnist.submit(estimator)",
      "metadata": {},
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "run",
      "metadata": {},
      "execution_count": 6,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>pytorchmnist</td><td>pytorchmnist_1545340099288</td><td>azureml.scriptrun</td><td>Queued</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/3a06a10f-ae29-4924-b6a7-dda0ea91d347/resourceGroups/Ralph/providers/Microsoft.MachineLearningServices/workspaces/wrecker/experiments/pytorchmnist/runs/pytorchmnist_1545340099288\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>",
            "text/plain": "Run(Experiment: pytorchmnist,\nId: pytorchmnist_1545340099288,\nType: azureml.scriptrun,\nStatus: Queued)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "RunDetails(run).show()",
      "metadata": {},
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d07efce30ae465bbbd6a707be510f41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'NOTSET',…"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "すべて完了すると、次のようになります:\n\n![AzureML Run](https://raw.githubusercontent.com/sethjuarez/pytorchintro/master/images/run_widget.png)\n\n実際に、損失関数は時間の経過とともに（平均して）減少し、モデルの精度が上がったことに注意してください。learning_rate パラメータを変更して試してみてください。詳しくは、[Azure Machine Learning service でモデルのハイパーパラメーターを調整する](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters) を参照してください。\n\nさて、どのようにしてこれらの素晴らしいチャートを表示させられたのか疑問に思うかもしれません。これは Azure ML サービスが、あなたがすでにやっていたことに対して実用的な価値を付加してくれるところです。[いくつか](https://github.com/sethjuarez/pytorchintro/blob/master/train.py#L156-L166) の [戦略的](https://github.com/sethjuarez/pytorchintro/blob/master/train.py#L121-L122) に [配置](https://github.com/sethjuarez/pytorchintro/blob/master/train.py#L142-L143) されたログステートメントを使用して、Azure ML サービスはこの出力を作成しました。実際、値が複数回ログに記録されると、テーブル内の項目ではなくチャートが自動的に作成されます。",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# モデル\nトレーニングがすべて完了して出力が完了したら、実際に特定の実験のすべての実行の出力を確認し、それを「公式な」ワークスペースモデルに昇格させることができます。重要なファイル（つまり私たちをお金持ちにしてくれるかもしれないモデル）が通常 Jeff という名前のコンピュータ上に置かれるのは素晴らしい機能です。また現在は、多くの人がモデルのバージョン管理さえしていません。以下のコードを実行してください。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "run.get_file_names()",
      "metadata": {},
      "execution_count": 8,
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['azureml-logs/60_control_log.txt',\n 'azureml-logs/80_driver_log.txt',\n 'outputs/model.pth',\n 'outputs/model.onnx',\n 'driver_log',\n 'azureml-logs/azureml.log',\n 'azureml-logs/55_batchai_execution.txt']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "model_file = 'outputs/model.pth'\nrun.download_file(name=model_file, output_file_path='model.pth')\nmodel = Model.register(ws, model_name='PyTorchMNIST', model_path='model.pth', \n                       description='CNN PyTorch Model')",
      "metadata": {},
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Registering model PyTorchMNIST\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "# イメージ\nモデルが完成したので、それをプロダクションで使用する場合は、モデルの使用方法を定義する必要があります。これはスコアリングまたは推論とも呼ばれます。Azure ML サービスでは、基本的に2つのメソッドが必要です:\n1. `init()`\n2. `run(raw)` JSON 文字列を取り込んで予測を返す\n\n最初にスコアスクリプトが実行される環境を記述し、それを環境ファイルにまとめる必要があります。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "myenv = CondaDependencies()\nmyenv.add_pip_package('numpy')\nmyenv.add_pip_package('torch')\nwith open('pytorchmnist.yml','w') as f:\n    print('Writing out {}'.format('pytorchmnist.yml'))\n    f.write(myenv.serialize_to_string())\n    print('Done!')",
      "metadata": {},
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Writing out pytorchmnist.yml\nDone!\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "次に、Azure ML サービスにスコアリングスクリプトの場所を通知する必要があります。[あらかじめ作っておきました](score.py)。ファイルを見ると、init() メソッドと run(raw) メソッドの両方が簡単に見つかるはずです。ファイルをローカルで実行して、正しい動作をしていることを確認することもできます。\n\nこれですべてが完成したので、イメージを作成しましょう。\n\n### バックグラウンドで何をしてるか気にしないのであれば、ここを読んではいけません\n基本的には、定義からdockerイメージを作成して、Workspace に表示される Azure Container Registry にプッシュします。\n\n**注** しばらく時間がかかります",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from azureml.core.image import ContainerImage, Image\n\n# create image\nimage_config = ContainerImage.image_configuration(execution_script=\"score.py\", \n                                runtime=\"python\", \n                                conda_file=\"pytorchmnist.yml\")\n\nimage = Image.create(ws, 'pytorchmnist', [model], image_config)\nimage.wait_for_creation(show_output=True)",
      "metadata": {},
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Creating image\nRunning.............................................\nSucceededImage creation operation finished for image pytorchmnist:5, operation \"Succeeded\"\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "# デプロイ\nイメージ作成をやめて、残りの展開プロセスを Azure Pipelines のようなものに移動したいかもしれません。このサービスを引き続きワークスペースにデプロイしたい場合は、以下を使用してください。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from azureml.core.webservice import Webservice, AciWebservice\n\nservice_name = 'pytorchmnist-svc'\n\n# check for existing service\nsvcs = [svc for svc in Webservice.list(ws) if svc.name==service_name]\nif len(svcs) == 1:\n    print('Deleting prior {} deployment'.format(service_name))\n    svcs[0].delete()\n\n# create service\naciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n                                            memory_gb=1, \n                                            description='simple MNIST digit detection')\nservice = Webservice.deploy_from_image(workspace=ws, \n                                    image=image, \n                                    name=service_name, \n                                    deployment_config=aciconfig)\nservice.wait_for_deployment(show_output=True)\nprint(service.scoring_uri)",
      "metadata": {},
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Deleting prior pytorchmnist-svc deployment\nCreating service\nRunning.........................\nSucceededACI service creation operation finished, operation \"Succeeded\"\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "イメージを ACI またはワークスペース Kubernetes クラスターにプッシュすることもできます。\n\n時々うまくいかないことがあります・・・もし実行時にそうなったら、実際の [logs](deploy.log) を見てください。!",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "with open('deploy.log','w') as f:\n    f.write(service.get_logs())",
      "metadata": {},
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# サービスの実行\nこれで動作しています。適切に動作しているか見てみましょう。テストデータをロードして乱数を試すことができます。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "digits = datasets.MNIST('data', train=True, download=True,\n                        transform=transforms.Compose([\n                            transforms.ToTensor(),\n                            transforms.Lambda(lambda x: x.reshape(28*28))\n                        ]),\n                        target_transform=transforms.Compose([\n                            transforms.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, y, 1))\n                        ])\n                     )\nprint(len(digits))",
      "metadata": {},
      "execution_count": 14,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "60000\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "インデックスとして基本的に最大60,000まで任意の数を選ぶことができます。サービスがどのように動作しているかを見るために何回か試してみてください。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import torch\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nX, Y = digits[57435]\nX = X * 255\nplt.imshow(255 - X.reshape(28,28), cmap='gray')\nprint(Y)",
      "metadata": {},
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<Figure size 432x288 with 1 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# This is a string representation of the image we will POST to the endpoint\nimage_str = ','.join(map(str, X.int().tolist()))\nprint(image_str)",
      "metadata": {
        "scrolled": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,63,255,253,119,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,19,178,240,253,252,246,75,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,19,178,252,252,253,252,252,193,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,101,252,252,252,253,252,252,223,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,63,240,252,252,252,253,252,252,223,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,63,255,253,253,240,140,114,253,253,84,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,19,178,240,253,252,233,71,0,159,252,252,84,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,19,178,252,252,253,233,74,0,0,253,252,239,65,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,101,252,252,252,253,151,0,0,0,253,252,195,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,141,240,252,252,252,253,27,0,0,0,253,252,118,0,0,0,0,0,0,0,0,0,0,0,0,0,0,63,255,253,253,178,140,0,0,0,0,141,255,253,56,0,0,0,0,0,0,0,0,0,0,0,0,0,73,240,253,252,233,56,0,0,0,0,73,240,253,176,6,0,0,0,0,0,0,0,0,0,0,0,0,76,234,252,253,233,74,0,0,0,0,13,187,252,253,136,0,0,0,0,0,0,0,0,0,0,0,0,57,234,252,252,240,71,0,0,0,0,10,156,252,252,178,9,0,0,0,0,0,0,0,0,0,0,0,0,163,252,252,252,63,0,0,0,0,0,85,252,252,252,63,0,0,0,0,0,0,0,0,0,0,0,0,0,226,253,253,253,0,0,0,0,0,176,253,253,253,190,0,0,0,0,0,0,0,0,0,0,0,0,0,0,100,252,252,252,163,85,117,225,225,253,252,252,179,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,85,252,252,252,253,252,252,252,252,253,233,164,19,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,28,199,252,252,253,252,252,252,252,240,71,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,112,189,253,252,252,236,112,63,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "import json\nimport requests\nservice_url = service.scoring_uri\nprint(service_url)\nr = requests.post(service_url, json={'image': image_str })\nr.json()",
      "metadata": {},
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "http://13.83.149.109:80/score\n"
        },
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'time': 0.104436,\n 'prediction': 0,\n 'scores': [0.995736837387085,\n  2.3327098475078856e-08,\n  0.003980344161391258,\n  0.00016383796173613518,\n  4.010713894331275e-08,\n  5.167449853615835e-05,\n  1.7358546756440774e-05,\n  4.9987315833277535e-06,\n  4.1949653677875176e-05,\n  3.171517391820089e-06]}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "## 最後に\nこの小さな旅が参考になっていればうれしい！ 私の目標は、機械学習の基本がそれほど悪いものではないことを示すことです。コメント、提案、または分からないところは一言教えてください。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}