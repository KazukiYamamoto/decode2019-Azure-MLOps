{
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat_minor": 2,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# 数字認識タスク\nNotebook の利用が初めての場合 - ようこそ！Notebook はコードの近くに結果が表示されるのを見ながら実行できる素晴らしいツールです。\n1. セルを実行するには、セルをクリックして SHIFT-Enter を押します。\n2. 何かが実行されると、変数はメモリに保存されます - それらを調べてください。\n\n## 始めましょう\n最初のセルは必要なライブラリをインポートするので、ここから始めましょう。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import torch\nimport numpy as np\nfrom PIL import Image\nimport torch.nn as nn\nimport torch.onnx as onnx\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": " ## データ!\n データがなければ、機械学習では何もできません。今回は「**28x28のベクトルで数字を予測できるか？**」という質問を与えられています。\n  \n それがすべて解決されたら、データを見てみる必要があります。次のセルは数字を視覚化するヘルパー関数です（健全性チェック）。\n Once that is all squared away we need to take a look at our data. The next cell is a helper function that visualizes the the digits (a sanity check).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def draw_digits(digits):\n    fig, axes = plt.subplots(6, 20, figsize=(18, 7),\n                            subplot_kw={'xticks':[], 'yticks':[]},\n                            gridspec_kw=dict(hspace=0.1, wspace=0.1))\n    for i, ax in enumerate(axes.flat):\n        X, y = digits[i]\n        ax.imshow(255 - X.reshape(28,28) * 255, cmap='gray')\n        ax.set_title('{:.0f}'.format(torch.argmax(y).item()))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "次のセルは、標準的な数値データセット（MNISTと呼ばれる）をダウンロードします。この呼び出しの transform 部分と target_transform 部分には、これから行うモデルにより適したデータにするための変換手順がいくつか追加されています。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "digits = datasets.MNIST('data', train=True, download=True,\n                        transform=transforms.Compose([\n                            transforms.ToTensor(),\n                            transforms.Lambda(lambda x: x.reshape(28*28))\n                        ]),\n                        target_transform=transforms.Compose([\n                            transforms.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, y, 1))\n                        ])\n                     )",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "ここでデータの健全性をチェックします。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "draw_digits(digits)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "xやyを表示して、気軽にデータを見てください。これらは本当に単なる数字です！それらを表示するといくつか奇妙に見えるかもしれません：\n\n1.「画像は 0～255 の 784個のベクトルではないのですか？」と思ったのではないですか。データは見た通りです！新しい範囲が 0～1 になるように255で割ってベクトルを正規化しただけです（数値がより正確になるようにしました）\n2. 「y が数値の答えだったのではないですか？代わりに 10次元のベクトルになっています」と思ったのではないですか。その通りです！これは答えの One-Hot 表現と呼ばれます。正解のインデクスの位置に \"1\" が入っています。繰り返しになりますが、これにより、これから作成するモデルで数値演算がよりよく機能するようになります。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "x, y = digits[0]\nprint(x)\nprint(y)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# モデルを選択する\nいくつかのデータが得られたので、今度はうまくいくと思われるモデルの選択を開始します。これがデータサイエンスの科学的な部分が出てくるところです：私たちは推測し、それから仮定が正しいかどうかチェックします。 784個の蛇口から10本の異なるホースに水を分配する必要がある水道管のようなモデルを想像してみてください。これらの784個の蛇口は数字の個々のピクセルを表し、最後の10個のホースは実際の数（または少なくとも水が最も多く出ているもののインデックス）を表します。私たちの仕事は今その間の配管を選ぶことです。\n\n次の3つのセルは、順に難しくなる 3つの異なる構造を表しています。\n\n1. 最初のモデルは単純な線形モデルです\n2. 2番目のモデルは3層ニューラルネットワークです\n3. 最後のモデルは全てが畳み込み層で構成されるニューラルネットワークです\n\nそれらがどのように働くかを完全に説明することはこのチュートリアルの範囲外ですが、ちょうど正しいインデックスから最も多くの水を押し出すために最後に正しい水圧を生み出すように調整されなければならない内部ノブで配管していると想像してください 。下のセルほど、配管とそれに対応する内部ノブがより複雑になります。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "class SimpleLinear(nn.Module):\n    def __init__(self):\n        super(SimpleLinear, self).__init__()\n        self.layer1 = nn.Linear(28*28, 10)\n\n    def forward(self, x):\n        x = self.layer1(x)\n        return F.softmax(x, dim=1)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "class NeuralNework(nn.Module):\n    def __init__(self):\n        super(NeuralNework, self).__init__()\n        self.layer1 = nn.Linear(28*28, 512)\n        self.layer2 = nn.Linear(512, 512)\n        self.output = nn.Linear(512, 10)\n\n    def forward(self, x):\n        x = F.relu(self.layer1(x))\n        x = F.relu(self.layer2(x))\n        x = self.output(x)\n        return F.softmax(x, dim=1)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = x.view(-1, 1, 28, 28)\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.softmax(x, dim=1)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# モデルパラメータの最適化\nいくつかのモデルがあるので、数字を認識するのに良い仕事ができるかどうか確認するために内部パラメータを最適化する時が来ました！それが訓練する方法を調整するために最適化アルゴリズムを与える際に使用する、いくつかのパラメータです - これらはハイパーパラメータと呼ばれます。次に示す2つの変数です。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "learning_rate = 1e-3\nbatch_size = 64\nepochs = 5",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "'learning_rate' は基本的に、アルゴリズムがモデルパラメータを学習する速度を指定します。あなたが「それを5000万に設定しましょう」と考えたとしましょう？これが悪い考えである理由の最も良い例えはゴルフです。私はひどいゴルファーなので（本当に？）私は本当に何も知りません - しかしあなたがショットを沈めようとしているのに（もう一度申し訳ありません）、毎回同じ距離ボールを打つようなものです。簡単でしょう？今いる場所から穴までの正確な距離を打ちなさい！完了です！今、あなたは穴がどこにあるのかわからないが、ただ一般的な方向を知っているとします。あなたが選ぶ距離は実際に重要です。距離が長すぎると穴を逃すことになり、それを叩くと再びオーバーシュートします。距離が小さすぎると、穴にたどり着くまでに時間がかかりますが、最終的にはその距離に到達するはずです。基本的には、1ショットあたりの正しい距離を推測してから試してみる必要があります。それが、「ホールインワン」のための正しいパラメーターを見つけるために、基本的に学習率がすることです。（さて、ゴルフの話は終わりです）\n\n\n以下は、すべてうまくいくようにするための3つのものです:\n1. **モデル** - 私たちが作ろうとしている関数であり、正解の数値を返すべきものです\n2. **コスト関数** (損失関数と呼ばれることもあります) 私はゴルフの話が終わったと約束したことを知っていますが、嘘をつきました。ねじれたゴルフゲームであなたが穴の一般的な方向を知っていると言ったのを覚えていますか？ コスト関数は穴までの距離を教えてくれます - ゼロになると穴に入ったことになるのです！実際の科学的な用語では、コスト関数は、モデルが正しい答えを得るのにどれほど悪いかを教えてくれます。ショットと同じように、コスト関数が減少するのを見るべきです。減少しないならば、何かが間違っています。そうならば、ショットの距離（または学習率）をもっと小さい値に変更して、もう一度試してみます。それでもうまくいかない場合は、モデルを変更してください。\n3. **オプティマイザー** - この部分は、実際にモデルパラメータを変更する部分です。それは我々が撃つべき方向の意味を持ち、正しい数字を予測するための最良の内部ノブを見つけるモデル内部のすべての値を更新します。ここでは、Binary Cross Entropy コスト関数を使用します。これがうまく機能することがわかっているからです。さまざまなシナリオに合わせて、さまざまなコスト関数を選択できます。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# where to run\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint('Using {} device'.format(device))\n\n# selected model\nmodel = SimpleLinear().to(device)\n#model = NeuralNework().to(device)\n#model = CNN().to(device)\nprint(model)\n\n# cost function used to determine best parameters\ncost = torch.nn.BCELoss()\n\n# used to create optimal parameters\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "'CUDA' について言及するのをすっかり忘れていました。基本的に for ループの中はすべての大きな行列の乗算問題であるため、GPUはこのプロセス全体をスピードアップします。PyTorchは基本的にどこで実行するか（CPUまたはCUDA - CUDA は計算を GPU に移行するためのプラットフォームです）をモデルに伝えるだけでいいので、PyTorchは素晴らしいです。\n\nそれでは、学習に進みます！データローダの仕事は、データセット全体（ここでは 60,000個の例とそれに対応するラベル）を反復処理することですが、処理するデータを batch_sizeの サイズごとに取得します。batch_sizeは選択する必要があるもう1つのハイパーパラメータです。'epoch' は、データセット全体をループする回数です（これもまた、実験の進行状況に基づいて選択したものです）。\n\n実行には時間がかかります。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# loader\ndataloader = DataLoader(digits, batch_size=batch_size, num_workers=0, pin_memory=True)\n\n# golfing time!\nfor t in range(epochs):\n    print('Epoch {}'.format(t))\n    print('-------------------------------')\n    # go through the entire dataset once\n    for batch, (X, Y) in enumerate(dataloader):\n        X, Y = X.to(device), Y.to(device)\n        # zero out gradient\n        optimizer.zero_grad()\n        # make a prediction on this batch!\n        pred = model(X)\n        # how bad is it?\n        loss = cost(pred, Y)\n        # compute gradients\n        loss.backward()\n        # update parameters\n        optimizer.step()\n        \n        if batch % 100 == 0:\n            print('loss: {:>10f}  [{:>5d}/{:>5d}]'.format(loss.item(), batch * len(X), len(dataloader.dataset)))\n            \n    print('loss: {:>10f}  [{:>5d}/{:>5d}]\\n'.format(loss.item(), len(dataloader.dataset), len(dataloader.dataset)))\n    \nprint('Done!')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "さて、ここでは実際に何をしたのでしょうか。素晴らしい質問です。最初の実行した SimpleLinear モデルから説明します。基本的に1つの行列と1つのベクトルを学習しています。それだけです（本当に大事なところではありません）。 実際に何をするのか、示します:\n\n\\begin{align}\nprediction = W \\cdot x + b\n\\end{align}\n\n\\begin{align}\n\\begin{bmatrix}\n\\hat{y}_1 \\\\ \\vdots \\\\ \\hat{y}_{10}\n\\end{bmatrix}_{10 \\times 1} = \n\\begin{bmatrix}\nw_{1,1} &  \\ldots &  w_{1,784} \\\\\n\\vdots    & \\ddots &  \\\\\nw_{10,1}  & \\ldots & w_{10, 784} \\\\\n\\end{bmatrix}_{10 \\times 784} \n\\cdot\n\\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_{783} \\\\ x_{784}\\end{bmatrix}_{784 \\times 1}\n + \n\\begin{bmatrix}\nb_1 \\\\ \\vdots \\\\ b_{10}\n\\end{bmatrix}_{10 \\times 1}\n\\end{align}\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "行列 W とベクトル b は、SimpleLinear モデルが学習するものです。出力は 10×1 行列で、最大値を持っているものが予測したい数値のインデックスです。アルゴリズムが 2つの変数（およびサイズ）について学習した内容を見てみましょう:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "for p in model.parameters():\n    print(p.shape)\n    print(p)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# 動作していますか？\n正常に機能しているかどうかを判断する最良の方法は、学習プロセスで使用されていないデータでモデルをテストすることです。幸いなことに、そのようなデータセットがあります（これは基本的に、既に使用したデータとは分けておかれたものです）。以前と同じ方法でそれをすべてロードし、それらが異なることを示すためにそれらを表示してみます。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "test_digits = datasets.MNIST('data', train=False, download=True,\n                        transform=transforms.Compose([\n                            transforms.ToTensor(),\n                            transforms.Lambda(lambda x: x.reshape(28*28))\n                        ]),\n                        target_transform=transforms.Compose([\n                            transforms.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, y, 1))\n                        ])\n                     )\ndraw_digits(test_digits)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "最初の数値でテストしましょう（7 です）。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "x, y = test_digits[0]\nx = x.to(device).view(1, 28*28)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "評価に使用するモデル（推論とも呼ばれます）を指定して、これまでに使ったことのない数値を渡します。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "model.eval()\nwith torch.no_grad():\n    pred = model(x)\n    pred = pred.to('cpu').detach()[0]\n    \nprint(pred)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "予測された数字が実際の数字と一致するかどうか見てみましょう:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pred.argmax(0), y.argmax(0)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "**すべて** のテストデータに対してどれだけうまくいっているか見てみましょう！",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# data loader for test digits\ntest_dataloader = DataLoader(test_digits, batch_size=64, num_workers=0, pin_memory=True)\n\n# set model to evaluation mode\nmodel.eval()\ntest_loss = 0\ncorrect = 0\n\n# loop! \nwith torch.no_grad():\n    for batch, (X, Y) in enumerate(dataloader):\n        X, Y = X.to(device), Y.to(device)\n        pred = model(X)\n\n        test_loss += cost(pred, Y).item()\n        correct += (pred.argmax(1) == Y.argmax(1)).type(torch.float).sum().item()\n\ntest_loss /= len(dataloader.dataset)\ncorrect /= len(dataloader.dataset)\nprint('\\nTest Error:')\nprint('acc: {:>0.1f}%, avg loss: {:>8f}'.format(100*correct, test_loss))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# モデルの保存\nすべてのフレームワーク - 今回はPyTorch は異なります。モデルを内部フォーマットと ONNXフォーマットの両方で保存します（これらは大きな行列Wとベクトルbであることを覚えています）。これらは、数字を認識する必要があるたびに実行されるプログラムにアセットとしてロードすることができます。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# create dummy variable to traverse graph\nx = torch.randint(255, (1, 28*28), dtype=torch.float).to(device) / 255\nonnx.export(model, x, 'model.onnx')\nprint('Saved onnx model to model.onnx')\n\n# saving PyTorch Model Dictionary\ntorch.save(model.state_dict(), 'model.pth')\nprint('Saved PyTorch Model to model.pth')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# 試してみましょう！\nこれでプロセス全体が完了したので、上に戻って試してみてください。次のように変更してみましょう:\n1. 他のモデル（SimpleLinear を NeuralNetwork, CNN）を選択。他のモデルは、画像が最終的な答えを得るために通過する追加の行列（Wとb）を学習することを除けば、呼び出し方はほとんど同じです。\n2. learning_rate、batch_size、epochなどのハイパーパラメーター。 変更で結果が良くなったり悪くなったりしますか？ 92％は問題ないですが、他のモデルとハイパーパラメータの組み合わせのほうがいいでしょうか。\n\n## 最後に\nフィードバックを歓迎します！これは役に立ちましたか？ 分かりにくい部分はありますか？簡単にでもいいので教えてください。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}